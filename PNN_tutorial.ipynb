{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyperGlitch24/AMAI/blob/main/PNN_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08K1sSK7oWK9"
      },
      "source": [
        "# Progressive Neural Networks (PNNs)\n",
        "\n",
        "This notebook explores Progressive Neural Networks (PNNs) for Image classification. Unlike conventional NNs, PNNs usually assigns seperate columns for each new task, where each column denotes a neural network architecture. To leverage the information learned by the previous columns, PNNs use adapters to laterally connect the columns with each other. We will see in working how a multi-column Neural Network helps to sequentiall train on a set of sub-tasks without the problem of catastrophic forgetting.\n",
        "\n",
        "## TO-DOs:\n",
        "- Construct two sets of tasks: MNIST & Permuted Mnist\n",
        "- Design PNNS\n",
        "- Define two baselines\n",
        "    - Trained only on target task (Permuted Mnist) in this case - Baseline 1\n",
        "    - Pretrained on Source task, finetuned on target task\n",
        "        - All the layers are frozen leaving the final output layer - Baseline 2\n",
        "        - All the layers are trained - Baseline 3\n",
        "\n",
        "    This cases are quite similar to what we have seen in the transfer learning tutorial.  \n",
        "\n",
        "- Train and Evaluate on two contexts"
      ],
      "id": "08K1sSK7oWK9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk7K-BEpoWLB"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models0\n",
        "import torchvision\n",
        "from torchvision.utils import make_grid"
      ],
      "id": "sk7K-BEpoWLB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taU6bPeooWLC"
      },
      "outputs": [],
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "taU6bPeooWLC"
    },
    {
      "cell_type": "markdown",
      "id": "5c6728cb",
      "metadata": {
        "id": "5c6728cb"
      },
      "source": [
        "### Define your PNN\n",
        "\n",
        "- First define a single PNN column. It can be any Neural network of your choice\n",
        "- Define the PNN architecture where you have the possibility to add more than one column. Freeze one column. Train on the newly added column. Add lateral connections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VxM2gN5oWLD"
      },
      "outputs": [],
      "source": [
        "# PNN column\n",
        "class PNN_column(nn.Module):\n",
        "    def __init__(self, input_channels=1, output_classes=10):\n",
        "        super(PNN_column, self).__init__()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return out"
      ],
      "id": "6VxM2gN5oWLD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO4bNKSfoWLE"
      },
      "outputs": [],
      "source": [
        "# Progressive Neural Network definition\n",
        "class PNN(nn.Module):\n",
        "    def __init__(self, prev_model=None):\n",
        "        super(PNN, self).__init__()\n",
        "\n",
        "        \"\"\" TO-DO\n",
        "        1. Initialize the column_task with the appropriate input channels and output classes.\n",
        "        2. If prev_model is provided, copy its parameters to the column_task.\n",
        "        3. Define the adapters for the previous model if it exists.\n",
        "        \"\"\"\n",
        "        self.column_task = PNN_column()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" TO-DO\n",
        "        1. Forward function to .\n",
        "        2. If prev_model is provided, copy its parameters to the column_task.\n",
        "        3. Define the adapters for the previous model if it exists.\n",
        "        \"\"\"\n",
        "        return out"
      ],
      "id": "GO4bNKSfoWLE"
    },
    {
      "cell_type": "markdown",
      "id": "c595aa0f",
      "metadata": {
        "id": "c595aa0f"
      },
      "source": [
        "### Dataset Definition\n",
        "- Create two contexts: MNIST and Permuted MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bBeFoEmxoWLE",
        "outputId": "900bc649-9cbe-4e5a-dc06-784b91a2f68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1-3020491436.py, line 59)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1-3020491436.py\"\u001b[0;36m, line \u001b[0;32m59\u001b[0m\n\u001b[0;31m    permutations =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# MNIST Dataloaders\n",
        "transform = transforms.ToTensor()\n",
        "mnist_trainset = datasets.MNIST(root='/app/src/Mnist', train=True, download=True, transform= transforms.ToTensor())\n",
        "mnist_testset = datasets.MNIST(root='/app/src/Mnist', train=False, download=True, transform= transforms.ToTensor())\n",
        "\n",
        "len(mnist_trainset), len(mnist_testset) # 60000, 10000\n",
        "config = {'size': 28, 'channels': 1, 'classes': 10}\n",
        "\n",
        "#@title Visualization functions\n",
        "def multi_context_barplot(axis, accs, title=None):\n",
        "    '''Generate barplot using the values in [accs].'''\n",
        "    contexts = len(accs)\n",
        "    axis.bar(range(contexts), accs, color='k')\n",
        "    axis.set_ylabel('Testing Accuracy (%)')\n",
        "    axis.set_xticks(range(contexts), [f'Context {i+1}' for i in range(contexts)])\n",
        "    if title is not None:\n",
        "        axis.set_title(title)\n",
        "\n",
        "def plot_examples(axis, dataset, context_id=None):\n",
        "    '''Plot 25 examples from [dataset].'''\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=25, shuffle=True)\n",
        "    image_tensor, _ = next(iter(data_loader))\n",
        "    image_grid = make_grid(image_tensor, nrow=5, pad_value=1) # pad_value=0 would give black borders\n",
        "    axis.imshow(np.transpose(image_grid.numpy(), (1,2,0)))\n",
        "    if context_id is not None:\n",
        "        axis.set_title(\"Context {}\".format(context_id+1))\n",
        "    axis.axis('off')\n",
        "\n",
        "# Function to apply a given permutation the pixels of an image.\n",
        "def permutate_image_pixels(image, permutation):\n",
        "    '''Permutate the pixels of [image] according to [permutation].'''\n",
        "\n",
        "    return image\n",
        "\n",
        "# Class to create a dataset with images that have all been transformed in the same way.\n",
        "class TransformedDataset(torch.utils.data.Dataset):\n",
        "    '''To modify an existing dataset with a transform.\n",
        "    Useful for creating different permutations of MNIST without loading the data multiple times.'''\n",
        "\n",
        "    def __init__(self, original_dataset, transform=None, target_transform=None):\n",
        "        super().__init__()\n",
        "        self.dataset = original_dataset\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        (input, target) = self.dataset[index]\n",
        "        if self.transform:\n",
        "            input = self.transform(input)\n",
        "        if self.target_transform:\n",
        "            target = self.target_transform(target)\n",
        "        return (input, target)\n",
        "\n",
        "import numpy as np\n",
        "contexts = 2\n",
        "permutations =\n",
        "# Specify for each context the transformed train- and testset\n",
        "train_datasets = []\n",
        "test_datasets = []\n",
        "for context_id, perm in enumerate(permutations):\n",
        "\n",
        "# Visualize the contexts\n",
        "figure, axis = plt.subplots(1, contexts, figsize=(3*contexts, 4))\n",
        "\n",
        "for context_id in range(len(train_datasets)):\n",
        "    plot_examples(axis[context_id], train_datasets[context_id], context_id=context_id)\n"
      ],
      "id": "bBeFoEmxoWLE"
    },
    {
      "cell_type": "markdown",
      "id": "b8099256",
      "metadata": {
        "id": "b8099256"
      },
      "source": [
        "### Define the training and the evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-u77taqoWLG"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train(model, loader, optimizer, criterion, epochs=1):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for data, target in loader:\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "id": "7-u77taqoWLG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRECk5jYoWLH"
      },
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "\n",
        "    return correct / total"
      ],
      "id": "IRECk5jYoWLH"
    },
    {
      "cell_type": "markdown",
      "id": "3e7d0dab",
      "metadata": {
        "id": "3e7d0dab"
      },
      "source": [
        "### Now train the PNN network: first on the first context using the first column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgc9GSM5oWLH",
        "outputId": "c20abbb8-5df3-44f4-e1ea-92895ee1f7cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Task 1 (MNIST)\n",
            "Epoch 1, Loss: 0.0116\n",
            "Epoch 2, Loss: 0.0078\n",
            "Epoch 3, Loss: 0.0078\n",
            "Task 1 Test Accuracy: 0.988\n"
          ]
        }
      ],
      "source": [
        "# Train Task 1 (original MNIST)\n",
        "model1 = PNN()\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"Training Task 1 (MNIST)\")\n",
        "train(model1, train_loader, optimizer1, criterion, epochs=3)\n",
        "acc1 = evaluate(model1, test_loader)\n",
        "print(\"Task 1 Test Accuracy:\", acc1)"
      ],
      "id": "Cgc9GSM5oWLH"
    },
    {
      "cell_type": "markdown",
      "id": "b67daabd",
      "metadata": {
        "id": "b67daabd"
      },
      "source": [
        "### Then train on the second context using the second column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgMheyyeoWLI"
      },
      "outputs": [],
      "source": [
        "# Save the frozen model for Task 1\n",
        "frozen_model = copy.deepcopy(model1.task_model)"
      ],
      "id": "UgMheyyeoWLI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vpg4_lBJoWLI",
        "outputId": "be9bcb90-ab46-4d9e-fb1d-52f20cc999b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Task 2 (Permuted MNIST)\n",
            "Epoch 1, Loss: 0.0809\n",
            "Epoch 2, Loss: 0.4536\n",
            "Epoch 3, Loss: 0.2599\n",
            "Task 2 Test Accuracy: 0.9626\n"
          ]
        }
      ],
      "source": [
        "# Train Task 2 (Permuted MNIST)\n",
        "model2 = PNN(prev_model=frozen_model)\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\nTraining Task 2 (Permuted MNIST)\")\n",
        "train(model2, train_loader2, optimizer2, criterion, epochs=3)\n",
        "acc2 = evaluate(model2, test_loader2)\n",
        "print(\"Task 2 Test Accuracy:\", acc2)"
      ],
      "id": "Vpg4_lBJoWLI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK3PLutPoWLI"
      },
      "source": [
        "## Train and Evaluate the baselines\n",
        "- Now define all the baselines mentioned above\n",
        "- Individually train on the second context\n",
        "- Compare the results"
      ],
      "id": "vK3PLutPoWLI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bb0a004",
      "metadata": {
        "id": "7bb0a004"
      },
      "outputs": [],
      "source": [
        "\"\"\" TO-DO  \"\"\"\n",
        "\n",
        "## Baseline 1\n",
        "\n",
        "\"\"\"\n",
        " Baseline 1: Train a new model for target task without reusing previous knowledge\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "## Baseline 2\n",
        "\n",
        "\"\"\" Baseline 2: Train a new model on the target task, but initialize it with the parameters of the previous model and freeze the previous model's parameters.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "## Baseline 3\n",
        "\"\"\" Baseline 3: Train a new model on the target task, but initialize it with the parameters of the previous model and fine-tune all the model parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be1a9a7e",
      "metadata": {
        "id": "be1a9a7e"
      },
      "source": [
        "### Plot the performance of PNNs and the baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c92740",
      "metadata": {
        "id": "59c92740"
      },
      "outputs": [],
      "source": [
        "\"\"\" TO-DO  \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a39f877",
      "metadata": {
        "id": "8a39f877"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}